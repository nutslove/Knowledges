## `st.rerun()`と`st.button()`の`on_click`（callback関数）を組み合わせて画面をリフレッシュする
- `st.button()`の`on_click`で指定した関数（callback関数）内で`session_state`をクリアし、`st.button()`処理内で`st.rerun()`を実行する  
  ```python
    import streamlit as st
    import json
    import urllib
    import os
    import datetime
    import time
    import string
    import random
    from opensearchpy import OpenSearch
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langchain_core.runnables.history import RunnableWithMessageHistory
    from langchain_community.chat_message_histories import StreamlitChatMessageHistory

    os.environ["OPENAI_ENDPOINT"] = "https://api.openai.com/v1/chat/completions"
    os.environ["OPENAI_API_KEY"] = "xxxxxxxxxxxx"

    opensearch_client = OpenSearch(
        hosts = [{'host': <OpenSearch APIのエンドポイント>, 'port': <OpenSearch API Port>}],
        http_compress = True,
        http_auth = ('admin', 'admin'),
        use_ssl = True,
        verify_certs = False,
        ssl_assert_hostname = False,
        ssl_show_warn = False
    )

    def init_state(key: str, value: any = None) -> None:
        if key not in st.session_state:
            st.session_state[key] = value

    def general_llm_call(user_input: str) -> str:
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", "You are an AI chatbot having a conversation with a human. Answer must be in japanese."),
                MessagesPlaceholder(variable_name="history"),
                ("human", "{question}"),
            ]
        )
        llm = ChatOpenAI(model="gpt-4o",temperature=0.1,max_tokens=None)
        msgs = StreamlitChatMessageHistory(key="chat_messages")
        chain = prompt | llm
        chain_with_history = RunnableWithMessageHistory(
            chain,
            get_session_history = lambda message_history: msgs,
            input_messages_key = "question",
            history_messages_key = "history",
        )
        config = {"configurable": {"session_id": "any"}}

        res = chain_with_history.invoke({"question": user_input}, config)
        return res.content

    def rag_call(user_input: str, index_name:str, mode: str, num_of_ref_docs: int) -> str:
        json_data = json.dumps({
            'query': user_input,
            'index_name': index_name,
            'mode': mode,
            'num_of_ref_docs': num_of_ref_docs
        }).encode('utf-8')
        req = urllib.request.Request("https://<RAG検索システム>", data=json_data, headers={'Content-Type': 'application/json'}, method='POST')
        with urllib.request.urlopen(req) as res:
            res_body = res.read().decode('utf-8')

        res_body_dict = json.loads(res_body)
        ref_contents = ""
        ref_docs = ""
        for ref_docs_info in res_body_dict["cognitive_search_top"]:
            ref_contents += f"{ref_docs_info['content']}\n"
            ref_docs += f"- Title: *{ref_docs_info['title']}*\n- URL: *{ref_docs_info['url']}*\n"

        system_prompt = """
        - You are an AI assistant that helps people find information.
        - Answer must be in Japanese.
        - Don't complete user messages.
        - Estimate user intent and suggest solutions.
        """
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt),
                MessagesPlaceholder(variable_name="history"),
                ("human", """
                Answer the following question using the EMBEDDING_TEXT

                ## question
                {question}

                ## EMBEDDING_TEXT
                {retriever}
                """)
            ]
        )
        llm = ChatOpenAI(model="gpt-4o",temperature=0.1,max_tokens=None)
        msgs = StreamlitChatMessageHistory(key="chat_messages")
        chain = prompt | llm
        chain_with_history = RunnableWithMessageHistory(
            chain,
            get_session_history = lambda message_history: msgs,
            input_messages_key = "question",
            history_messages_key = "history",
        )
        config = {"configurable": {"session_id": "any"}}
        res = chain_with_history.invoke({"question": user_input, "retriever": ref_contents}, config)

        res = res.content + "\n ##### ■ 参照Docs\n" + ref_docs
        return res

    ## ★この部分
    def reset_chat():
        del st.session_state["messages"]
        del st.session_state["chat_messages"]
        del st.session_state["message_id"]

    def main():
        init_state("messages", [{"role": "assistant", "content": "初めまして、ChatBotです。質問にお答えします。"}])
        init_state("message_id", str(time.time_ns())+''.join(random.choice(string.ascii_lowercase) for _ in range(5)))

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        with st.sidebar:
            index_name = st.selectbox('質問対象システムを選択してください',["Portal","一般的な質問"])
            mode = st.selectbox("検索方式を選択してください", ["hybrid","vector","semantic"])
            num_of_ref_docs = st.slider("検索件数を選択してください",1,5,1)

        if user_input := st.chat_input("質問を入力してください"):
            st.session_state.messages.append({"role": "user", "content": user_input})
            with st.chat_message("user"):
                st.markdown(user_input)

            with st.spinner("Thinking..."):
                if index_name == "一般的な質問":
                    res = general_llm_call(user_input)
                else:
                    res = rag_call(user_input, index_name, mode, num_of_ref_docs)

            with st.chat_message("assistant"):
                st.markdown(res)
                st.session_state.messages.append({"role": "assistant", "content": res})

            # OpenSearchに会話履歴をingest
            document = {
                'message_id': st.session_state.message_id,
                'question': user_input,
                'answer': res,
                'timestamp': datetime.datetime.now().isoformat(timespec='seconds')
            }

            opensearch_client.index(
                index = 'chatbot-index',
                body = document,
                refresh = True
            )

            ## ★この部分
            if st.button('会話リセット', type="primary", icon=":material/refresh:", on_click=reset_chat):
                st.rerun()

    if __name__ == '__main__':
        st.set_page_config(
            page_title="ChatBot",
            page_icon=":books:",
            menu_items={
                'About': 'beta version'
            }
        )

        ## 画面左上の"Deploy"ボタンとSettingボタンを隠すための設定
        st.markdown("""
            <style>
                #MainMenu {visibility: hidden;}
                .stAppDeployButton {visibility: hidden;}
            </style>
        """, unsafe_allow_html=True)

        st.title("ChatBot :books:")

        main()
  ```

> [!CAUTION]
> ```python
> def reset_chat():
>    del st.session_state["messages"]
>    del st.session_state["chat_messages"]
>    del st.session_state["message_id"]
>    st.rerun()
>
> def main():
>    st.button('会話リセット', type="primary", icon=":material/refresh:", on_click=reset_chat)
> ```
> 上記のようにcallback関数内で`st.rerun()`を実行すると以下の警告が出る。  
> ![](../image/streamlit_rerun_warning.jpg)  
> `st.rerun()`はcallback関数内で使ってはいけないみたい。  
> https://discuss.streamlit.io/t/menu-between-multipages-calling-st-rerun-within-a-callback-is-a-no-op/53827

> [!CAUTION]
> ```python
> if st.button('会話リセット', type="primary", icon=":material/refresh:"):
>    del st.session_state["messages"]
>    del st.session_state["chat_messages"]
>    del st.session_state["message_id"]
>    st.rerun()
> ```
> 上記のように`button`の中で`session_state`をクリア後、`st.rerun()`してもなぜか画面のリフレッシュがされない。

> [!WARNING]  
> - `st.experimental_rerun()`は廃止となり、1.39.0から使えなくなった
>   - https://docs.streamlit.io/develop/api-reference/execution-flow/st.experimental_rerun